{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b8d404",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables of different data types\n",
    "integer_var = 10         # Integer\n",
    "decimal_var = 3.14       # Float\n",
    "string_var = \"Hello, Jupyter!\"  # String\n",
    "boolean_var = True       # Boolean\n",
    "\n",
    "# Print each variable and its type\n",
    "print(\"Integer Variable:\")\n",
    "print(\"Value:\", integer_var)\n",
    "print(\"Type:\", type(integer_var))\n",
    "\n",
    "print(\"\\nFloat Variable:\")\n",
    "print(\"Value:\", decimal_var)\n",
    "print(\"Type:\", type(decimal_var))\n",
    "\n",
    "print(\"\\nString Variable:\")\n",
    "print(\"Value:\", string_var)\n",
    "print(\"Type:\", type(string_var))\n",
    "\n",
    "print(\"\\nBoolean Variable:\")\n",
    "print(\"Value:\", boolean_var)\n",
    "print(\"Type:\", type(boolean_var))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7594d0",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0346d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: [10, 20, 30, 40, 50]\n",
      "First Element: 10\n",
      "Third Element: 30\n",
      "Last Element: 50\n"
     ]
    }
   ],
   "source": [
    "# Creating a List\n",
    "my_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "# Accessing elements based on index\n",
    "first_element = my_list[0]  # Accessing the 1st element\n",
    "third_element = my_list[2]  # Accessing the 3rd element\n",
    "last_element = my_list[-1]  # Accessing the last element\n",
    "\n",
    "print(\"List:\", my_list)\n",
    "print(\"First Element:\", first_element)\n",
    "print(\"Third Element:\", third_element)\n",
    "print(\"Last Element:\", last_element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41578645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple: ('apple', 'banana', 'cherry', 'date', 'elderberry')\n",
      "Second Element: banana\n",
      "Fourth Element: date\n",
      "Last Element: elderberry\n"
     ]
    }
   ],
   "source": [
    "# Creating a Tuple\n",
    "my_tuple = ('apple', 'banana', 'cherry', 'date', 'elderberry')\n",
    "\n",
    "# Accessing elements based on index\n",
    "second_element = my_tuple[1]  # Accessing the 2nd element\n",
    "fourth_element = my_tuple[3]  # Accessing the 4th element\n",
    "last_element = my_tuple[-1]  # Accessing the last element\n",
    "\n",
    "print(\"Tuple:\", my_tuple)\n",
    "print(\"Second Element:\", second_element)\n",
    "print(\"Fourth Element:\", fourth_element)\n",
    "print(\"Last Element:\", last_element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b1772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: {'name': 'Alice', 'age': 25, 'city': 'New York', 'job': 'Engineer', 'salary': 75000}\n",
      "Name: Alice\n",
      "Age: 25\n",
      "City: New York\n"
     ]
    }
   ],
   "source": [
    "# Creating a Dictionary\n",
    "my_dict = {'name': 'Alice', 'age': 25, 'city': 'New York', 'job': 'Engineer', 'salary': 75000}\n",
    "\n",
    "# Accessing elements based on keys\n",
    "name = my_dict['name']  # Accessing value associated with 'name'\n",
    "age = my_dict['age']  # Accessing value associated with 'age'\n",
    "city = my_dict['city']  # Accessing value associated with 'city'\n",
    "\n",
    "print(\"Dictionary:\", my_dict)\n",
    "print(\"Name:\", name)\n",
    "print(\"Age:\", age)\n",
    "print(\"City:\", city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c5b09",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be44383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter marks for Subject 1: 99\n",
      "Enter marks for Subject 2: 98\n",
      "Enter marks for Subject 3: 99\n",
      "Grade: A\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate grade based on average\n",
    "def calculate_grade():\n",
    "    # Taking input for marks in three subjects\n",
    "    subject1 = float(input(\"Enter marks for Subject 1: \"))\n",
    "    subject2 = float(input(\"Enter marks for Subject 2: \"))\n",
    "    subject3 = float(input(\"Enter marks for Subject 3: \"))\n",
    "\n",
    "    # Calculating the average\n",
    "    average = (subject1 + subject2 + subject3) / 3\n",
    "\n",
    "    # Determining the grade\n",
    "    if average >= 90:\n",
    "        print(\"Grade: A\")\n",
    "    elif 80 <= average < 90:\n",
    "        print(\"Grade: B\")\n",
    "    elif 70 <= average < 80:\n",
    "        print(\"Grade: C\")\n",
    "    else:\n",
    "        print(\"Grade: Fail\")\n",
    "\n",
    "# Call the function\n",
    "calculate_grade()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc46374",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b08747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a positive integer n: 45\n",
      "The sum of all even numbers between 1 and 45 is: 506\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the sum of all even numbers between 1 and n\n",
    "def sum_of_evens(n):\n",
    "    # Initialize sum\n",
    "    total = 0\n",
    "\n",
    "    # Loop through numbers from 1 to n\n",
    "    for i in range(1, n + 1):\n",
    "        if i % 2 == 0:  # Check if the number is even\n",
    "            total += i\n",
    "\n",
    "    return total\n",
    "\n",
    "# Input: Positive integer n\n",
    "n = int(input(\"Enter a positive integer n: \"))\n",
    "\n",
    "# Check if the input is valid\n",
    "if n > 0:\n",
    "    # Call the function and display the result\n",
    "    result = sum_of_evens(n)\n",
    "    print(f\"The sum of all even numbers between 1 and {n} is: {result}\")\n",
    "else:\n",
    "    print(\"Please enter a positive integer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8241bb0d",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0f9ea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text: HELLO\n",
      "\n",
      "Word frequencies:\n",
      "hello: 1\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the frequency of each word\n",
    "def word_frequency(text):\n",
    "    # Convert text to lowercase and split into words\n",
    "    words = text.lower().split()\n",
    "\n",
    "    # Create a dictionary to store word frequencies\n",
    "    frequency = {}\n",
    "\n",
    "    # Count the occurrences of each word\n",
    "    for word in words:\n",
    "        word = word.strip(\",.?!;:'\\\"\")  # Remove punctuation\n",
    "        if word in frequency:\n",
    "            frequency[word] += 1\n",
    "        else:\n",
    "            frequency[word] = 1\n",
    "\n",
    "    return frequency\n",
    "\n",
    "# Input: Text from the user\n",
    "text = input(\"Enter a text: \")\n",
    "\n",
    "# Call the function and get the word frequencies\n",
    "frequencies = word_frequency(text)\n",
    "\n",
    "# Display the word frequencies\n",
    "print(\"\\nWord frequencies:\")\n",
    "for word, count in frequencies.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e2595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tharun\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: spacy in c:\\users\\tharun\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (75.4.0)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (1.25.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tharun\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\tharun\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811efe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286aa9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to preprocess text using NLTK and spaCy\n",
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Tokenize the text using NLTK\n",
    "    tokens = word_tokenize(text_lower)\n",
    "\n",
    "    # Remove stopwords using NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "\n",
    "    # Use spaCy for lemmatization\n",
    "    doc = nlp(\" \".join(filtered_tokens))\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Sample text input\n",
    "text = \"\"\"\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction \n",
    "between computers and humans through natural language. NLP allows computers to understand, interpret, \n",
    "and generate human language in a way that is meaningful.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the text\n",
    "processed_text = preprocess_text(text)\n",
    "\n",
    "# Display the processed text\n",
    "print(\"Processed Text:\")\n",
    "print(\" \".join(processed_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a3e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9564cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275df1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7634d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3eab6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
